{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import PyTorch modules"
      ],
      "metadata": {
        "id": "RfBeheCNos9-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaRjQJEDokeO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.datasets import VOCDetection\n",
        "from torchvision import transforms as T\n",
        "import os\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets"
      ],
      "metadata": {
        "id": "EjYFfoM3sHvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "SHARED_PATH = Path(\"drive/MyDrive/Colab Notebooks/Shared\")\n",
        "HRSC_PATH = SHARED_PATH / \"HRSC2016_Final_Splits\"\n",
        "DOTA_PATH = SHARED_PATH / \"DOTA_Final_Splits\"\n",
        "\n",
        "print(\"HRSC important subfolders:\", [f\"{subfolder.name}/{path.name}\" for subfolder in HRSC_PATH.iterdir() for path in subfolder.iterdir()])\n",
        "print(\"DOTA important subfolders:\", [f\"{subfolder.name}/{path.name}\" for subfolder in DOTA_PATH.iterdir() for path in subfolder.iterdir()])\n",
        "\n",
        "HRSC_TRAIN_IMAGES = HRSC_PATH/ \"train/images\"\n",
        "HRSC_TRAIN_ANNOTATIONS = HRSC_PATH / \"train/annotations\"\n",
        "HRSC_VAL_IMAGES = HRSC_PATH / \"val/images\"\n",
        "HRSC_VAL_ANNOTATIONS = HRSC_PATH / \"val/annotations\"\n",
        "HRSC_TEST_IMAGES = HRSC_PATH / \"test/images\"\n",
        "HRSC_TEST_ANNOTATIONS = HRSC_PATH / \"test/annotations\"\n",
        "\n",
        "DOTA_TRAIN_IMAGES = DOTA_PATH / \"train/images\"\n",
        "DOTA_TRAIN_ANNOTATIONS = DOTA_PATH / \"train/hbb\"\n",
        "DOTA_VAL_IMAGES = DOTA_PATH / \"val/images\"\n",
        "DOTA_VAL_ANNOTATIONS = DOTA_PATH / \"val/hbb\"\n",
        "DOTA_TEST_IMAGES = DOTA_PATH / \"test/images\"\n",
        "DOTA_TEST_ANNOTATIONS = DOTA_PATH / \"test/hbb\""
      ],
      "metadata": {
        "id": "PT9GIwS8sX4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore datasets"
      ],
      "metadata": {
        "id": "yp-lr_Prs6PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama\n",
        "from colorama import Fore, Style\n",
        "\n",
        "def explore_header(dataset: str, subfolder: str):\n",
        "  print(\"Exploring\", Fore.GREEN + dataset + Style.RESET_ALL, Fore.MAGENTA + subfolder + Style.RESET_ALL, \"folder...\")\n",
        "\n",
        "def explore(images_folder: Path, ext: str):\n",
        "  files = list(images_folder.glob(f\"*.{ext}\"))\n",
        "  print(f\"Number of {ext.upper()} files:\", len(files))\n",
        "  print(f\"{ext.upper()} sample files:\", [path.name for path in files[:3]])\n",
        "\n",
        "explore_header(\"HRSC\", \"train\")\n",
        "explore(HRSC_TRAIN_IMAGES, \"bmp\")\n",
        "explore(HRSC_TRAIN_ANNOTATIONS, \"xml\")\n",
        "\n",
        "print()\n",
        "\n",
        "explore_header(\"HRSC\", \"val\")\n",
        "explore(HRSC_VAL_IMAGES, \"bmp\")\n",
        "explore(HRSC_VAL_ANNOTATIONS, \"xml\")\n",
        "\n",
        "print()\n",
        "\n",
        "explore_header(\"HRSC\", \"test\")\n",
        "explore(HRSC_TEST_IMAGES, \"bmp\")\n",
        "explore(HRSC_TEST_ANNOTATIONS, \"xml\")\n",
        "\n",
        "print()\n",
        "\n",
        "explore_header(\"DOTA\", \"train\")\n",
        "explore(DOTA_TRAIN_IMAGES, \"png\")\n",
        "explore(DOTA_TRAIN_ANNOTATIONS, \"txt\")\n",
        "\n",
        "print()\n",
        "\n",
        "explore_header(\"DOTA\", \"val\")\n",
        "explore(DOTA_VAL_IMAGES, \"png\")\n",
        "explore(DOTA_VAL_ANNOTATIONS, \"txt\")\n",
        "\n",
        "print()\n",
        "\n",
        "explore_header(\"DOTA\", \"test\")\n",
        "explore(DOTA_TEST_IMAGES, \"png\")\n",
        "explore(DOTA_TEST_ANNOTATIONS, \"txt\")"
      ],
      "metadata": {
        "id": "jf-wMzlNs8Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define label parsers"
      ],
      "metadata": {
        "id": "ELZ-eU81tvbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "HRSC_CLASSES = {}\n",
        "DOTA_CLASSES = {}\n",
        "\n",
        "\n",
        "def parse_hrsc_labels(label_path: Path):\n",
        "  boxes = []\n",
        "  labels = []\n",
        "  tree = ET.parse(label_path.as_posix())\n",
        "  root = tree.getroot()\n",
        "\n",
        "  # Get image dimensions\n",
        "  width = int(root.find('.//Img_SizeWidth').text)\n",
        "  height = int(root.find('.//Img_SizeHeight').text)\n",
        "\n",
        "  objects = root.findall(\".//HRSC_Object\")\n",
        "  for obj in objects:\n",
        "    try:\n",
        "      # Bounds\n",
        "      xmin = float(obj.find('box_xmin').text)\n",
        "      ymin = float(obj.find('box_ymin').text)\n",
        "      xmax = float(obj.find('box_xmax').text)\n",
        "      ymax = float(obj.find('box_ymax').text)\n",
        "\n",
        "      # Category\n",
        "      class_id = int(obj.find('Class_ID').text)\n",
        "      if class_id not in HRSC_CLASSES:\n",
        "        HRSC_CLASSES[class_id] = len(HRSC_CLASSES)\n",
        "      class_id_index = HRSC_CLASSES[class_id]\n",
        "\n",
        "      boxes.append([xmin, ymin, xmax, ymax])\n",
        "      labels.append(class_id_index)  # TODO add 1 for background index 0 ?\n",
        "\n",
        "    except Exception as e:\n",
        "      print(Fore.RED + \"Warning\" + Style.RESET_ALL + f\": Could not parse object in {label_path.as_posix()}: {e}\")\n",
        "      continue\n",
        "\n",
        "  return boxes, labels\n",
        "\n",
        "\n",
        "def parse_dota_labels(label_path: Path):\n",
        "  boxes = []\n",
        "  labels = []\n",
        "\n",
        "  # Find all objects\n",
        "  for line in itertools.islice(label_path.read_text().splitlines(), 2, None):  # Start from line index 2\n",
        "    try:\n",
        "      obj = line.strip().split()\n",
        "      x1, y1, x2, y2, x3, y3, x4, y4, category, difficulty = (*map(float, obj[:8]), *obj[8:])\n",
        "\n",
        "      # Bounds\n",
        "      xmin = min(x1, x2, x3, x4)\n",
        "      ymin = min(y1, y2, y3, y4)\n",
        "      xmax = max(x1, x2, x3, x4)\n",
        "      ymax = max(y1, y2, y3, y4)\n",
        "\n",
        "      # Category\n",
        "      if category not in DOTA_CLASSES:\n",
        "        DOTA_CLASSES[category] = len(DOTA_CLASSES)\n",
        "      class_id_index = DOTA_CLASSES[category]\n",
        "\n",
        "      boxes.append([xmin, ymin, xmax, ymax])\n",
        "      labels.append(class_id_index)  # TODO add 1 for background index 0 ?\n",
        "\n",
        "    except Exception as e:\n",
        "      print(Fore.RED + \"Warning\" + Style.RESET_ALL + f\": Could not parse object in {label_path.as_posix()}: {e}\")\n",
        "      continue\n",
        "\n",
        "  return boxes, labels"
      ],
      "metadata": {
        "id": "c1iomq0mtvAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch dataset structure"
      ],
      "metadata": {
        "id": "MVdX-5_GpPse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pathlib import Path\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "class TorchDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, images_folder: Path, annotations_folder: Path, label_parser, transforms=None) -> None:\n",
        "    super().__init__()\n",
        "    self.label_parser = label_parser\n",
        "    self.transforms = transforms\n",
        "    images = [f for f in images_folder.iterdir() if f.suffix in (\".jpg\", \".png\", \".bmp\")] if images_folder.exists() else []\n",
        "    annotations = [f for f in annotations_folder.iterdir() if f.suffix in (\".xml\", \".txt\")] if annotations_folder.exists() else []\n",
        "\n",
        "    # Keep only images/annotations one-to-one correspondences\n",
        "    image_set = set(f.stem for f in images)\n",
        "    annotation_set = set(f.stem for f in annotations)\n",
        "    self.ids = image_set.intersection(annotation_set)\n",
        "    self.images = {f.stem: f for f in images if f.stem in self.ids}\n",
        "    self.annotations = {f.stem: f for f in annotations if f.stem in self.ids}\n",
        "    self.ids = list(self.ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    id = self.ids[index]\n",
        "    image_path = self.images[id]\n",
        "    label_path = self.annotations[id]\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    boxes, labels = self.label_parser(label_path)\n",
        "    target = {\n",
        "        \"boxes\": torch.as_tensor(boxes, dtype=torch.float32),\n",
        "        \"labels\": torch.as_tensor(labels, dtype=torch.int64),\n",
        "    }\n",
        "    if self.transforms:\n",
        "      image = self.transforms(image)\n",
        "    return image, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ids)\n",
        "\n",
        "  def compute_total_number_of_objects(self, max_workers=8):\n",
        "    def count_objects(id):\n",
        "      boxes, _ = self.label_parser(self.annotations[id])\n",
        "      return len(boxes)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "      results = executor.map(count_objects, self.ids)\n",
        "    return sum(results)"
      ],
      "metadata": {
        "id": "4usg0yx6pTIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare datasets for PyTorch"
      ],
      "metadata": {
        "id": "-kt6q3Jqwu-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO use transforms?\n",
        "\n",
        "print(\"Preparing HRSC training dataset...\")\n",
        "HRSC_TRAIN_DATASET = TorchDataset(HRSC_TRAIN_IMAGES, HRSC_TRAIN_ANNOTATIONS, parse_hrsc_labels)\n",
        "print(f\"...Dataset prepared: {HRSC_TRAIN_DATASET.compute_total_number_of_objects()} total objects\")\n",
        "print(\"HRSC training dataset sample:\", HRSC_TRAIN_DATASET.ids[:5])\n",
        "\n",
        "print(\"Preparing HRSC validation dataset...\")\n",
        "HRSC_VAL_DATASET = TorchDataset(HRSC_VAL_IMAGES, HRSC_VAL_ANNOTATIONS, parse_hrsc_labels)\n",
        "print(f\"...Dataset prepared: {HRSC_VAL_DATASET.compute_total_number_of_objects()} total objects\")\n",
        "print(\"HRSC validation dataset sample:\", HRSC_VAL_DATASET.ids[:5])\n",
        "\n",
        "print(\"Preparing HRSC testing dataset...\")\n",
        "HRSC_TEST_DATASET = TorchDataset(HRSC_TEST_IMAGES, HRSC_TEST_ANNOTATIONS, parse_hrsc_labels)\n",
        "print(f\"...Dataset prepared: {HRSC_TEST_DATASET.compute_total_number_of_objects()} total objects\")\n",
        "print(\"HRSC testing dataset sample:\", HRSC_TEST_DATASET.ids[:5])\n",
        "\n",
        "print(\"Preparing DOTA training dataset...\")\n",
        "DOTA_TRAIN_DATASET = TorchDataset(DOTA_TRAIN_IMAGES, DOTA_TRAIN_ANNOTATIONS, parse_dota_labels)\n",
        "print(f\"...Dataset prepared: {DOTA_TRAIN_DATASET.compute_total_number_of_objects()} total objects\")\n",
        "print(\"DOTA training dataset sample:\", DOTA_TRAIN_DATASET.ids[:5])\n",
        "\n",
        "print(\"Preparing DOTA validation dataset...\")\n",
        "DOTA_VAL_DATASET = TorchDataset(DOTA_VAL_IMAGES, DOTA_VAL_ANNOTATIONS, parse_dota_labels)\n",
        "print(f\"...Dataset prepared: {DOTA_VAL_DATASET.compute_total_number_of_objects()} total objects\")\n",
        "print(\"DOTA validation dataset sample:\", DOTA_VAL_DATASET.ids[:5])\n",
        "\n",
        "print(\"Preparing DOTA testing dataset...\")\n",
        "DOTA_TEST_DATASET = TorchDataset(DOTA_TEST_IMAGES, DOTA_TEST_ANNOTATIONS, parse_dota_labels)\n",
        "print(f\"...Dataset prepared: {DOTA_TEST_DATASET.compute_total_number_of_objects()} total objects\")\n",
        "print(\"DOTA testing dataset sample:\", DOTA_TEST_DATASET.ids[:5])"
      ],
      "metadata": {
        "id": "c3s53360w44K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define PyTorch Faster R-CNN model"
      ],
      "metadata": {
        "id": "c2O8GWlr2sif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FasterRCNNModel:\n",
        "  def __init__(self, train_dataset: TorchDataset, val_dataset: TorchDataset, test_dataset: TorchDataset, class_names: list) -> None:\n",
        "    self.train_dataset = train_dataset\n",
        "    self.val_dataset = val_dataset\n",
        "    self.test_dataset = test_dataset\n",
        "    self.class_names = class_names\n",
        "    self.class_names.append(\"__background__\")\n",
        "    self.num_classes = len(class_names)\n",
        "\n",
        "    self.train_loader = torch.utils.data.DataLoader(self.train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "    self.val_loader = torch.utils.data.DataLoader(self.val_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "    self.test_loader = torch.utils.data.DataLoader(self.test_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "    self.model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    self.in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
        "    self.model.roi_heads.box_predictor = FastRCNNPredictor(self.in_features, self.num_classes)\n",
        "    self.model.to(DEVICE)\n",
        "\n",
        "  def train(self, num_epochs=50):\n",
        "    # TODO Add an \"RoI Learner\" after ROI pooling to predit rotated offsets (dx, dy, dw, dh, dtheta)\n",
        "    # TODO Replace roi_align with torchvision.ops.roi_align_rotated\n",
        "    # TODO Add rotation-aware losses (see comments in training loop)\n",
        "\n",
        "    # Example optimizer\n",
        "    optimizer = torch.optim.SGD(self.model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      print(f\"Starting epoch {epoch+1}/{num_epochs}...\")\n",
        "\n",
        "      # Training loop\n",
        "      train_loss = 0.0\n",
        "      self.model.train()\n",
        "      for images, targets in self.train_loader:\n",
        "        images = [img.to(DEVICE) for img in images]\n",
        "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = self.model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += losses.item()\n",
        "\n",
        "      lr_scheduler.step()\n",
        "\n",
        "      # Validation loop\n",
        "      val_loss = 0.0\n",
        "      self.model.eval()\n",
        "      with torch.no_grad():\n",
        "        for images, targets in self.val_loader:\n",
        "          images = [img.to(DEVICE) for img in images]\n",
        "          targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "          loss_dict = self.model(images, targets)\n",
        "          losses = sum(loss for loss in loss_dict.values())\n",
        "          val_loss += losses.item()\n",
        "\n",
        "      print(f\"...Finished epoch {epoch+1}/{num_epochs}, Training loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}\")\n",
        "\n",
        "    torch.save(self.model.state_dict(), \"faster_rcnn_model.pth\")\n",
        "\n",
        "  def test_results(self):\n",
        "    self.model.eval()\n",
        "    all_boxes, all_labels, all_scores = [], [], []\n",
        "    with torch.no_grad():\n",
        "      for images, _ in self.test_loader:\n",
        "        images = [img.to(DEVICE) for img in images]\n",
        "        predictions = self.model(images)\n",
        "        for prediction in predictions:\n",
        "          boxes, labels, scores = prediction['boxes'], prediction['labels'], prediction['scores']\n",
        "          all_boxes.append(boxes.cpu().numpy())\n",
        "          all_labels.append(labels.cpu().numpy())\n",
        "          all_scores.append(scores.cpu().numpy())\n",
        "    return all_boxes, all_labels, all_scores\n",
        "\n",
        "# TODO\n",
        "# -------------------------------------------------------------------\n",
        "# FUTURE UPGRADE: RoI TRANSFORMER INTEGRATION\n",
        "# -------------------------------------------------------------------\n",
        "# To integrate the RoI Transformer:\n",
        "#   1. Add a custom RRoI Learner layer:\n",
        "#        fc = nn.Linear(roi_feature_dim, 5)\n",
        "#        -> predicts (dx, dy, dw, dh, dtheta)\n",
        "#   2. Compute rotated boxes and apply torchvision.ops.roi_align_rotated\n",
        "#   3. Replace standard SmoothL1 loss with rotated IoU or 5D regression loss\n",
        "#   4. Use torchvision.ops.box_iou_rotated() and nms_rotated() for matching and inference\n",
        "#   5. Dataset boxes should include rotation (x, y, w, h, theta)"
      ],
      "metadata": {
        "id": "Y1hJruRt2yVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare dataset models"
      ],
      "metadata": {
        "id": "20AyC4tw8HuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HRSC_MODEL = FasterRCNNModel(HRSC_TRAIN_DATASET, HRSC_VAL_DATASET, HRSC_TEST_DATASET, [id for id, _ in sorted(HRSC_CLASSES.items(), key=lambda item: item[1])])\n",
        "DOTA_MODEL = FasterRCNNModel(DOTA_TRAIN_DATASET, DOTA_VAL_DATASET, DOTA_TEST_DATASET, [id for id, _ in sorted(DOTA_CLASSES.items(), key=lambda item: item[1])])"
      ],
      "metadata": {
        "id": "tFPaQy7t8MaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train dataset models"
      ],
      "metadata": {
        "id": "eLEecH3487cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training HRSC model...\")\n",
        "HRSC_MODEL.train()\n",
        "print(\"...HRSC model trained.\")\n",
        "\n",
        "print(\"Training DOTA model...\")\n",
        "DOTA_MODEL.train()\n",
        "print(\"...DOTA model trained.\")"
      ],
      "metadata": {
        "id": "-_VvrW4p9NVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate dataset models"
      ],
      "metadata": {
        "id": "fo9xloKX89bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hrsc_boxes, hrsc_labels, hrsc_scores = HRSC_MODEL.test_results()\n",
        "dota_boxes, dota_labels, dota_scores = DOTA_MODEL.test_results()\n",
        "# TODO analyse results and visualize them"
      ],
      "metadata": {
        "id": "sthCTKuq9Pmb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}